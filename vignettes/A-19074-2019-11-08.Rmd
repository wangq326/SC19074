---
title: "Homework of Chap 7"
author: '19074'
date: "2019/11/13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Exercise 7.6

+ Efron and Tibshirani discuss the scor(bootstrap) test score data on 88 students who took examinations in ﬁve subjects [84, Table7.1], [188, Table1.2.1]. The ﬁrst two tests (mechanics, vectors) were closed book and the last three tests (algebra, analysis, statistics) were open book. Each row of the data frame is a set of scores $(x_{i1},x_{i2},x_{i3},x_{i4},x_{i5})$ for the $i^{th}$ student. 
  + Use a panel display to display the scatter plots for each pair of test scores. 
  + Compare the plot with the sample correlation matrix. 
  + Obtain bootstrap estimates of the standard errors for each of the following estimates: 
    + $\hat\rho_{12}=\hat\rho(mec, vec)$, 
    + $\hat\rho_{34}=\hat\rho(alg, ana)$, 
    + $\hat\rho_{35}=\hat\rho(alg, sta)$, 
    + $\hat\rho_{45}=\hat\rho(ana, sta)$. 

## Answer

```{r}
library(bootstrap)
data(scor)
plot(scor) #the scatter plots for each pair of test scores
```

```{r}
cor(scor) #the sample correlation matrix
```

```{r}
set.seed(9986)
library(boot) #for boot function

cor_12 <- function(x, i){ 
  #want correlation of columns 1 and 2 
  cor(x[i,1], x[i,2])
}
obj1 <- boot(data = scor, statistic = cor_12, R = 2000)

cor_34 <- function(x, i){ 
  cor(x[i,3], x[i,4])
}
obj2 <- boot(data = scor, statistic = cor_34, R = 2000)

cor_35 <- function(x, i){ 
  cor(x[i,3], x[i,5])
}
obj3 <- boot(data = scor, statistic = cor_35, R = 2000)

cor_45 <- function(x, i){ 
  cor(x[i,4], x[i,5])
}
obj4 <- boot(data = scor, statistic = cor_45, R = 2000)

bootstrap_cor <- c(mean(obj1$t),mean(obj2$t),mean(obj3$t),mean(obj4$t))
s <- c(sd(obj1$t),sd(obj2$t),sd(obj3$t),sd(obj4$t))
s_c <- cor(scor)
sample_cor=c(cor12=s_c[1,2],cor34=s_c[3,4],cor35=s_c[3,5],cor45=s_c[4,5])

rbind(sample_cor,bootstrap_cor,se_estimation=s)
```

+ From the scatter diagram, we can see that the correlation between the first two variables and the last three variables is relatively strong, while the correlation between the first two variables and the last three variables is not strong.

+ Comparing the sample covariance matrix, we can get the same conclusion as the above one.

+ Finally, we give the sample estimators, bootstrap estimators and estimators of bootstrap standard errors of these four statistics.



# Project 7.B

+ Repeat Project 7.A for the sample skewness statistic. 
+ Compare the coverage rates for normal populations (skewness 0) and $\chi^{2}(5)$ distributions (positive skewness).

## Recall 7.A

+ Conduct a Monte Carlo study to estimate the coverage probabilities of the standard normal bootstrap conﬁdence interval, the basic bootstrap conﬁdence interval, and the percentile conﬁdence interval. 
+ Sample from a normal population and check the empirical coverage rates for the sample mean. Find the proportion of times that the conﬁdence intervals miss on the left, and the porportion of times that the conﬁdence intervals miss on the right.

```{r}
library(boot) #for boot and boot.ci 
set.seed(666)

mean.boot <- function(dat, ind) { 
  #function to compute the statistic mean
  y <- dat[ind] 
  mean(y)
}

M=200
cr <- ml <- mr <- matrix(0,nrow = M,ncol = 3)
for (i in 1:M) {
  norm_s <- rnorm(100)
  obj5 <- boot(norm_s, statistic = mean.boot, R = 2000)
  a1 <- boot.ci(obj5, type = c("norm","basic","perc"))
  
  # the empirical coverage rates for the sample mean
  cr[i,1] <- ifelse(a1[["normal"]][2]<0&a1[["normal"]][3]>0,1,0)
  cr[i,2] <- ifelse(a1[["basic"]][4]<0&a1[["basic"]][5]>0,1,0)
  cr[i,3] <- ifelse(a1[["percent"]][4]<0&a1[["percent"]][5]>0,1,0)
  
  # the proportion of times that the conﬁdence intervals miss on the left
  ml[i,1] <- (a1[["normal"]][3]<0)
  ml[i,2] <- (a1[["basic"]][5]<0)
  ml[i,3] <- (a1[["percent"]][5]<0)
  
  # the porportion of times that the conﬁdence intervals miss on the right
  mr[i,1] <- (a1[["normal"]][2]>0)
  mr[i,2] <- (a1[["basic"]][4]>0)
  mr[i,3] <- (a1[["percent"]][4]>0)
  
}

coverage_rate <- c(norm=mean(cr[,1]),basic=mean(cr[,2]),percent=mean(cr[,3]))
p_on_left <- c(norm=mean(ml[,1]),basic=mean(ml[,2]),percent=mean(ml[,3]))
p_on_right <- c(norm=mean(mr[,1]),basic=mean(mr[,2]),percent=mean(mr[,3]))

rbind(coverage_rate,p_on_left,p_on_right)
```

## Solution of project 7.B

```{r}
library(boot) 
set.seed(9986)

sk.boot <- function(dat,ind) {
  # function to compute the statistic skewness 
  x <- dat[ind]
  xbar <- mean(x) 
  m3 <- mean((x - xbar)^3) 
  m2 <- mean((x - xbar)^2) 
  return(m3 / m2^1.5) 
} 


M=200
crnorm <- crchisq <- matrix(0,nrow = M,ncol = 3)
for (i in 1:M) {
  norm_s <- rnorm(100)
  obj6 <- boot(norm_s, statistic = sk.boot, R = 2000) # bootstrap
  a2 <- boot.ci(obj6, type = c("norm","basic","perc")) # bootstrap ci for 3 methods
  
  # the empirical coverage rates for the sample sk
  crnorm[i,1] <- (a2[["normal"]][2]<0&a2[["normal"]][3]>0)
  crnorm[i,2] <- (a2[["basic"]][4]<0&a2[["basic"]][5]>0)
  crnorm[i,3] <- (a2[["percent"]][4]<0&a2[["percent"]][5]>0)
}

for (i in 1:M) {
  chi5_s <- rchisq(100,df=5)
  obj7 <- boot(chi5_s, statistic = sk.boot, R = 2000)
  a3 <- boot.ci(obj7, type = c("norm","basic","perc"))
  
  # the empirical coverage rates for the sample sk
  crchisq[i,1] <- (a3[["normal"]][2]<4/sqrt(10)&a3[["normal"]][3]>4/sqrt(10))
  crchisq[i,2] <- (a3[["basic"]][4]<4/sqrt(10)&a3[["basic"]][5]>4/sqrt(10))
  crchisq[i,3] <- (a3[["percent"]][4]<4/sqrt(10)&a3[["percent"]][5]>4/sqrt(10))
}

norm_coverage_rate <- c(norm=mean(crnorm[,1]),basic=mean(crnorm[,2]),percent=mean(crnorm[,3]))
chi5_coverage_rate <- c(norm=mean(crchisq[,1]),basic=mean(crchisq[,2]),percent=mean(crchisq[,3]))

rbind(norm_coverage_rate,chi5_coverage_rate)
```

+ We can find that under bootstrap, the coverage rates of skewness confidence interval of chi-square distribution with a degree of freedom of 5 is about 0.75, far less than the nominal confidence level. 
+ However, the coverage rates of skewness confidence interval of normal population is close to the nominal confidence level.
+ Moreover, in terms of confidence interval coverage rates, the confidence intervals obtained by the three methods have high similarity.





