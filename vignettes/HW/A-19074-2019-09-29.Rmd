---
title: "A-19074-2019-09-29"
author: '19074'
date: "2019/10/5"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1 Question : exercise 3.4 From Page 74

The Rayleigh density [156, Ch.18] is $$
f(x)=\frac{x}{\sigma^{2}} e^{-x^{2} /\left(2 \sigma^{2}\right)}, \quad x \geq 0, \sigma>0.
$$Develop an algorithm to generate random samples from a Rayleigh(σ) distribution. Generate Rayleigh(σ) samples for several choices of σ>0 and check that the mode of the generated samples is close to the theoretical mode σ (check the histogram). 

## 1.1 Answer : the acceptance-rejection methood

Here we assign $g(x)$ to be the pdf of Gamma(2,$1/\sigma^2$), and c is $Gamma\left(2\right)\sigma^4e^{1/2\sigma^2}$.

In this exercise, we choose $\sigma^2$ to be 1, 4, 0.25, 16.

### 1.1.1 Sampling function via the acceptance-rejection methood
```{r}
# generate n r.v. from f(x) with sigma2
rRayleigh <- function(n, sigma2){
  j<-k<-0
  y <- numeric(n)
  while (k < n) {
  u <- runif(1)
  j <- j + 1
  x <- rgamma(1,shape = 2,scale = sigma2) # random variate from g
  if (exp(-(x^2-2*x+1)/(2*sigma2)) > u) {
    #we accept x
    k <- k + 1
    y[k] <- x
    }
  }
  hist(y, prob = TRUE)  
  y <- seq(0, 20, .002)
  lines(y, y*exp(-y^2/(2*sigma2))/sigma2) 
}
```

### 1.1.2 $\sigma^2=1$

```{r}
rRayleigh(100000,1)
```

### 1.1.3 $\sigma^2=4$

```{r}
rRayleigh(100000,4)
```

### 1.1.4 $\sigma^2=0.25$

```{r}
rRayleigh(100000,0.25)
```

### 1.1.5 $\sigma^2=16$

```{r}
rRayleigh(100000,16)
```

## 1.2 Analysis of the result of exercise 3.4

From the histogram, it is easy to find that the simulated sampling obtained by the acceptance-rejection method is very close to the real Rayleigh distribution sampling result, which can indicate that we have obtained the result with good performance. Further, we can also check that the mode σ of the generated samples is close to the theoretical mode σ. 

# 2 Question : exercise 3.11 from page 75

Generate a random sample of size 1000 from a normal location mixture. The components of the mixture have N(0,1)and N(3,1)distributions with mixing probabilities p1 and p2 =1−p1. Graph the histogram of the sample with density superimposed, for p1 =0.75. Repeat with diﬀerent values for p1 and observe whether the empirical distribution of the mixture appears to be bimodal. Make a conjecture about the values of p1 that produce bimodal mixtures. 

## 2.1 Answer : Transformation methods

### 2.1.1 Sampling function via transformation methods

```{r}
normlocationmixture <- function(n, p){
  x1 <- rnorm(n, 0, 1)
  x2 <- rnorm(n, 3, 1)
  r <- rbinom(n, 1, p)
  z <- r*x1+(1-r)*x2
  hist(z, probability = TRUE)
  z <- seq(-5, 10, .001)
  lines(z,p*dnorm(z,0,1)+(1-p)*dnorm(z,3,1))
}
```

### 2.1.2 p1=0.75

```{r}
normlocationmixture(10000, 0.75)
```

### 2.1.3 Try different values of p1

```{r}
p <- seq(0.05,1,.05)
for (i in c(1:20)){
  normlocationmixture(10000,p[i])
  print(p[i])
}
```

## 2.2 Analysis of the result of exercise 3.11

By taking different values of p1, we find that in some cases there will be bimodal mixture. Through experiments, an approximate guess can be made that when 0.25<p1<0.75, bimodal mixture will occur.

# 3 Question : exercise 3.18 from page 76

Write a function to generate a random sample from a Wd(Σ,n) (Wishart) distribution for n>d+1≥1, based on Bartlett’s decomposition.

## 3.1 Answer : Wishart distribution based on Bartlett's decomposition

Notice that here we are required to sample from Wishart distribution based on Bartlett's decomposition. However, it's easy to find that generating a sample by its definition is much more convenient. So, in this exercise both method will be implemented.

### 3.1.1 Sampling function via Bartlett's decomposition

```{r}
Wdsampling1 <- function(Sigma, d, n){
  library(MASS)
  L <- chol(Sigma) # Sigma=LL'
  T <- matrix(0, nrow = d, ncol = d)
  for (i in (1:d)){
    T[i,i] <- sqrt(rchisq(1,n-i+1))
    for (j in 1:i-1){
      T[i,j] <- rnorm(1)
    }
  } 
  S <- L%*%T%*%t(T)%*%t(L)  #Bartlett's decomposition
  S
}
```

### 3.1.2 Generate a sample

```{r}
Wdsampling1(diag(3)+1, 3, 5)
```

### 3.1.3 Sampling function via its definition

This method is from https://www.datalearner.com/blog/1051508471131357.

```{r}
Wdsampling2 <- function(Sigma, d, n){
  library(MASS)
  Id <- diag(d)  
  Md <- numeric(d)
  x <- mvrnorm(n, Md, Id)  #x[i,]~N(0,Id)
  L <- chol(Sigma)
  for (i in (1:n)){
      A <- x[i,]%*%t(x[i,])
  } # generate a wishart(Id,d,n) sample
  S <- L%*%A%*%t(L)
  S
}
```

### 3.1.4 Generate a sample

```{r}
Wdsampling2(diag(3)+1, 3, 5)
```




